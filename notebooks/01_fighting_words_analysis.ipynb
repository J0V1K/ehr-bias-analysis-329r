{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fighting Words Analysis: Racial Disparities in Discharge Instructions\n",
        "\n",
        "This notebook performs Fighting Words analysis to identify statistically significant differences in word usage across racial groups in hospital discharge instructions.\n",
        "\n",
        "## Analysis Steps:\n",
        "1. Load and preprocess discharge instruction data\n",
        "2. Apply Fighting Words algorithm (Monroe et al., 2008)\n",
        "3. **Apply FDR correction** for multiple comparisons\n",
        "4. Visualize and interpret results\n",
        "\n",
        "## Key Innovation:\n",
        "We add Benjamini-Hochberg False Discovery Rate (FDR) correction to account for testing thousands of words simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "import convokit\n",
        "from convokit import Corpus, FightingWords\n",
        "\n",
        "# Import our custom modules\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "from src.data_loader import load_for_analysis\n",
        "from statistical_analysis import fighting_words_with_correction, report_statistics\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data\n",
        "\n",
        "We use the custom data loader which:\n",
        "- Loads from `data/` directory\n",
        "- Standardizes race categories\n",
        "- Provides reproducible sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load discharge instructions\n",
        "# For full analysis, remove sample_size parameter\n",
        "df = load_for_analysis(\n",
        "    filepath='../data/merged_file_sample=100k_section=dischargeinstructions.csv',\n",
        "    sample_size=None,  # Use all 100k records\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Loaded {len(df)} discharge instructions\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text, stemm=False):\n",
        "    \"\"\"\n",
        "    Tokenize and clean text for Fighting Words analysis.\n",
        "    \n",
        "    Steps:\n",
        "    1. Tokenize into words\n",
        "    2. Lowercase\n",
        "    3. Remove punctuation\n",
        "    4. Remove stopwords\n",
        "    5. Remove tokens with numbers\n",
        "    6. Optionally apply stemming\n",
        "    \"\"\"\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "    tokens = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
        "    \n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    tokens = [token for token in tokens if not any(char.isdigit() for char in token)]\n",
        "    \n",
        "    if stemm:\n",
        "        stemmer = PorterStemmer()\n",
        "        tokens = [stemmer.stem(token) for token in tokens]\n",
        "    \n",
        "    tokens = [token for token in tokens if token]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def sep_instruct(text):\n",
        "    \"\"\"\n",
        "    Extract discharge instructions section from full clinical note.\n",
        "    \"\"\"\n",
        "    pattern = r\"(?smi)^\\s*Discharge Instructions(?::)?\\n(.*?)^\\s*Followup Instructions\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return \" \".join(clean_text(match.group(1).strip()))\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def get_corpus(sample_df):\n",
        "    \"\"\"\n",
        "    Convert DataFrame to ConvoKit corpus for Fighting Words.\n",
        "    \"\"\"\n",
        "    df = sample_df.copy()\n",
        "    \n",
        "    df['id'] = df['note_id'].astype(str)\n",
        "    df['speaker'] = df['subject_id'].astype(str)\n",
        "    df['conversation_id'] = df.index.astype(str)\n",
        "    df['reply_to'] = None\n",
        "    df['timestamp'] = pd.to_datetime(df['charttime'])\n",
        "    df['meta.race'] = df['race']\n",
        "    df['meta.gender'] = df['gender']\n",
        "    \n",
        "    utterances_df = df[['id', 'timestamp', 'text', 'speaker', 'reply_to', \n",
        "                         'conversation_id', 'meta.race', 'meta.gender']]\n",
        "    \n",
        "    corpus = Corpus.from_pandas(utterances_df=utterances_df)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocess Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract discharge instructions and clean\n",
        "print(\"Preprocessing text...\")\n",
        "df_clean = df.dropna(subset=['text']).copy()\n",
        "df_clean['text'] = df_clean['text'].progress_apply(sep_instruct)\n",
        "df_clean = df_clean[df_clean['text'] != ''].reset_index(drop=True)\n",
        "\n",
        "print(f\"After cleaning: {len(df_clean)} records\")\n",
        "print(f\"Race distribution:\")\n",
        "print(df_clean['race'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fighting Words Analysis\n",
        "\n",
        "Compare word usage between two racial groups using log-odds with Dirichlet prior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select racial groups to compare\n",
        "race1 = \"WHITE\"\n",
        "race2 = \"BLACK\"\n",
        "\n",
        "print(f\"Comparing {race1} vs {race2}\")\n",
        "\n",
        "# Create corpus\n",
        "corpus = get_corpus(df_clean)\n",
        "\n",
        "# Run Fighting Words\n",
        "fw = FightingWords(ngram_range=(1,1))\n",
        "fw.fit(\n",
        "    corpus,\n",
        "    class1_func=lambda utt: race1 in utt.meta['race'],\n",
        "    class2_func=lambda utt: race2 in utt.meta['race']\n",
        ")\n",
        "\n",
        "# Get results\n",
        "results = fw.summarize(corpus, plot=True, class1_name=race1, class2_name=race2)\n",
        "print(f\"\\nTotal words tested: {len(results)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Apply FDR Correction (CRITICAL)\n",
        "\n",
        "**This is the most important statistical fix.**\n",
        "\n",
        "When testing thousands of words, we expect many false positives:\n",
        "- With p < 0.05 and 2,557 words tested \u2192 expect ~128 false positives!\n",
        "- We use Benjamini-Hochberg FDR correction to control for this\n",
        "\n",
        "This addresses the main methodological critique from the code review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply FDR correction\n",
        "print(\"Applying Benjamini-Hochberg FDR correction...\")\n",
        "results_corrected = fighting_words_with_correction(\n",
        "    results,\n",
        "    z_col='z-score',\n",
        "    alpha=0.05,\n",
        "    method='fdr_bh'\n",
        ")\n",
        "\n",
        "# Generate statistical report\n",
        "stats = report_statistics(\n",
        "    results_corrected,\n",
        "    comparison_name=f\"{race1} vs {race2}\",\n",
        "    class1_name=race1,\n",
        "    class2_name=race2\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Examine Significant Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top words after FDR correction\n",
        "significant = results_corrected[results_corrected['significant_fdr']].copy()\n",
        "\n",
        "print(f\"Significant words after FDR correction: {len(significant)}\")\n",
        "print(f\"\\nTop 10 words associated with {race1}:\")\n",
        "print(significant[significant['z-score'] > 0].sort_values('z-score', ascending=False).head(10))\n",
        "\n",
        "print(f\"\\nTop 10 words associated with {race2}:\")\n",
        "print(significant[significant['z-score'] < 0].sort_values('z-score').head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save corrected results\n",
        "import os\n",
        "os.makedirs('../results/fighting_words', exist_ok=True)\n",
        "\n",
        "output_file = f'../results/fighting_words/{race1}_vs_{race2}_FDR_corrected.csv'\n",
        "results_corrected.to_csv(output_file, index=False)\n",
        "print(f\"Results saved to {output_file}\")\n",
        "\n",
        "# Save only significant words\n",
        "significant_file = f'../results/fighting_words/{race1}_vs_{race2}_significant_only.csv'\n",
        "significant.to_csv(significant_file, index=False)\n",
        "print(f\"Significant words saved to {significant_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Interpretation\n",
        "\n",
        "### Key Findings:\n",
        "- **Before FDR correction:** Many words appeared \"significant\" (p < 0.05)\n",
        "- **After FDR correction:** Only truly robust differences remain\n",
        "- **Effect sizes:** Check the `effect_magnitude` column for practical significance\n",
        "\n",
        "### Caveats:\n",
        "1. **Correlation \u2260 Causation:** Word differences may reflect:\n",
        "   - Actual bias in clinical communication\n",
        "   - Differences in disease prevalence across racial groups\n",
        "   - Socioeconomic factors\n",
        "   \n",
        "2. **Single hospital:** Results from Beth Israel Deaconess may not generalize\n",
        "\n",
        "3. **Binary comparisons:** Intersectional effects (race \u00d7 gender) not captured\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
