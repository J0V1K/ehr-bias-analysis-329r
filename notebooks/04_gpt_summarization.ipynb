{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-3.5 Discharge Summary Generation\n",
        "\n",
        "This notebook generates discharge summaries using GPT-3.5 and compares them to original clinician-written instructions.\n",
        "\n",
        "## Analysis Steps:\n",
        "1. Load EHR discharge notes\n",
        "2. Extract relevant sections (HPI, Hospital Course)\n",
        "3. Generate summaries using GPT-3.5\n",
        "4. Save generated summaries for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Import custom data loader\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "from src.data_loader import load_for_analysis\n",
        "\n",
        "# Load environment variables (FIXED: was missing this!)\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize OpenAI client\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\n",
        "        \"OPENAI_API_KEY not found in environment variables.\\n\"\n",
        "        \"Please create a .env file with your API key:\\n\"\n",
        "        \"  cp .env.example .env\\n\"\n",
        "        \"  # Edit .env to add your key\"\n",
        "    )\n",
        "\n",
        "CLIENT = OpenAI(api_key=api_key)\n",
        "print(\"\u2713 OpenAI client initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a sample for GPT summarization\n",
        "# Note: Full dataset would be expensive to run through GPT-3.5\n",
        "df = load_for_analysis(\n",
        "    filepath='../data/sample=8k.csv',  # Using smaller sample\n",
        "    sample_size=None,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Loaded {len(df)} records for summarization\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Section Extraction Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sep_sections(text):\n",
        "    \"\"\"\n",
        "    Extract clinical note sections using regex patterns.\n",
        "    \"\"\"\n",
        "    sections = {\n",
        "        \"Chief Complaint\": \"\",\n",
        "        \"History of Present Illness\": \"\",\n",
        "        \"Family History\": \"\",\n",
        "        \"Brief Hospital Course\": \"\",\n",
        "        \"Transitional Issues\": \"\",\n",
        "        \"Discharge Instructions\": \"\",\n",
        "        \"Followup Instructions\": \"\",\n",
        "    }\n",
        "    \n",
        "    patterns = {\n",
        "        \"Chief Complaint\": r\"(?smi)^\\s*Chief Complaint(?::)?\\n(.*?)^\\s*Major Surgical or Invasive Procedure\",\n",
        "        \"History of Present Illness\": r\"(?smi)^\\s*History of Present Illness(?::)?\\n(.*?)^\\s*Past Medical History\",\n",
        "        \"Family History\": r\"(?smi)^\\s*Family History(?::)?\\n(.*?)^\\s*Physical Exam\",\n",
        "        \"Brief Hospital Course\": r\"(?smi)^\\s*Brief Hospital Course(?::)?\\n(.*?)^\\s*TRANSITIONAL ISSUES\",\n",
        "        \"Transitional Issues\": r\"(?smi)^\\s*TRANSITIONAL ISSUES(?::)?\\n(.*?)^\\s*Medications on Admission\",\n",
        "        \"Discharge Instructions\": r\"(?smi)^\\s*Discharge Instructions(?::)?\\n(.*?)^\\s*Followup Instructions\",\n",
        "        \"Followup Instructions\": r\"(?smi)^\\s*Followup Instructions(?::)?\\n(.*)\",\n",
        "    }\n",
        "    \n",
        "    for section, pattern in patterns.items():\n",
        "        match = re.search(pattern, text, re.DOTALL)\n",
        "        if match:\n",
        "            sections[section] = match.group(1).strip()\n",
        "    \n",
        "    return sections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. GPT-3.5 Summarization Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_discharge_summary(text):\n",
        "    \"\"\"\n",
        "    Generate discharge summary using GPT-3.5.\n",
        "    \n",
        "    Based on goals-of-care conversation prompt.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You are a healthcare provider preparing discharge instructions for a patient. \"\n",
        "        \"Below is clinical information from the hospital stay. \"\n",
        "        \"Please create clear, patient-friendly discharge instructions that include:\\n\"\n",
        "        \"1. Summary of hospital stay and treatment\\n\"\n",
        "        \"2. Key medications and instructions\\n\"\n",
        "        \"3. Follow-up care needed\\n\"\n",
        "        \"4. Warning signs to watch for\\n\\n\"\n",
        "    )\n",
        "    \n",
        "    # Example one-shot\n",
        "    example = (\n",
        "        \"Example:\\n\"\n",
        "        \"Dear Patient,\\n\\n\"\n",
        "        \"You were admitted for [condition]. During your stay, we [treatment]. \"\n",
        "        \"You are now stable and ready to go home.\\n\\n\"\n",
        "        \"Important instructions:\\n\"\n",
        "        \"- Take medications as prescribed\\n\"\n",
        "        \"- Follow up with your doctor\\n\"\n",
        "        \"- Call 911 if symptoms worsen\\n\\n\"\n",
        "    )\n",
        "    \n",
        "    response = CLIENT.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt + example + \"\\n\\nPatient Information:\\n\" + text,\n",
        "            }\n",
        "        ],\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        response_format={\"type\": \"text\"}\n",
        "    )\n",
        "    \n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Summaries\n",
        "\n",
        "**Note:** This cell can be expensive to run on large datasets. \n",
        "Start with a small sample to test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "os.makedirs('../results/GPTSummaries', exist_ok=True)\n",
        "\n",
        "# Generate summaries\n",
        "generated_summaries = []\n",
        "\n",
        "# IMPORTANT: Limit to small sample for testing\n",
        "test_sample = df.head(10)  # Start with just 10\n",
        "\n",
        "print(f\"Generating summaries for {len(test_sample)} records...\")\n",
        "print(\"Estimated cost: ~$0.01 per summary\\n\")\n",
        "\n",
        "for idx, row in test_sample.iterrows():\n",
        "    print(f\"Processing {idx+1}/{len(test_sample)}...\", end=\" \")\n",
        "    \n",
        "    # Extract sections\n",
        "    sections = sep_sections(row['text'])\n",
        "    \n",
        "    # Combine relevant sections\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"{key}:\\n{sections[key]}\"\n",
        "        for key in [\"Chief Complaint\", \"History of Present Illness\", \"Brief Hospital Course\"]\n",
        "        if sections[key]\n",
        "    ])\n",
        "    \n",
        "    # Generate summary\n",
        "    try:\n",
        "        summary = generate_discharge_summary(context)\n",
        "        \n",
        "        # Save to file\n",
        "        filename = f\"{row['subject_id']}_{row['gender']}_{row['race']}.txt\".replace(\"/\", \"\")\n",
        "        filepath = f\"../results/GPTSummaries/{filename}\"\n",
        "        \n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            f.write(summary)\n",
        "        \n",
        "        generated_summaries.append({\n",
        "            'subject_id': row['subject_id'],\n",
        "            'gender': row['gender'],\n",
        "            'race': row['race'],\n",
        "            'text': summary\n",
        "        })\n",
        "        \n",
        "        print(\"\u2713\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u2717 Error: {e}\")\n",
        "\n",
        "print(f\"\\nGenerated {len(generated_summaries)} summaries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataFrame from generated summaries\n",
        "generated_df = pd.DataFrame(generated_summaries)\n",
        "\n",
        "# Save to CSV\n",
        "output_file = '../results/GPTSummaries/generated_summaries.csv'\n",
        "generated_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved {len(generated_df)} summaries to {output_file}\")\n",
        "generated_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "With generated summaries, you can:\n",
        "1. Run Fighting Words analysis on GPT-generated vs original instructions\n",
        "2. Compare word usage patterns across racial groups\n",
        "3. Assess whether GPT-3.5 amplifies or reduces bias\n",
        "\n",
        "### Cost Estimation:\n",
        "- GPT-3.5-turbo: ~$0.001 per 1K tokens\n",
        "- Average discharge note: ~2K tokens\n",
        "- For 8,000 summaries: ~$16-$20\n",
        "\n",
        "### Ethical Considerations:\n",
        "- Generated summaries should NOT be used clinically\n",
        "- This is research only - not medical advice\n",
        "- MIMIC data use agreement restrictions apply"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}